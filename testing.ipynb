{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\stasj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\stasj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install tensorflow\n",
    "# !pip install --upgrade tensorflow-hub\n",
    "!pip3 install --upgrade opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'uninstall' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'uninstall' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!uninstall opencv-python\n",
    "!uninstall opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    # Convert the image to a tensor\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    \n",
    "    # Resize the image to the expected size\n",
    "    resized_tensor = tf.image.resize(input_tensor, [740, 740])\n",
    "\n",
    "    # Add an extra dimension for the batch size\n",
    "    input_tensor = tf.expand_dims(resized_tensor, 0)\n",
    "    \n",
    "    # Convert the tensor to tf.uint8\n",
    "    input_tensor = tf.cast(input_tensor, tf.uint8)\n",
    "    \n",
    "    return input_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(outputs):\n",
    "    # Get the number of detections\n",
    "    num_detections = len(outputs['detection_scores'])\n",
    "\n",
    "    # Get the detection classes and convert to numpy array\n",
    "    detection_classes = outputs['detection_classes'].numpy()\n",
    "\n",
    "    # Get the detection boxes and convert to numpy array\n",
    "    detection_boxes = outputs['detection_boxes'].numpy()\n",
    "\n",
    "    # Get the detection scores and convert to numpy array\n",
    "    detection_scores = outputs['detection_scores'].numpy()\n",
    "\n",
    "    # Filter out detections with low scores\n",
    "    min_score = 0.5\n",
    "    indices = np.where(detection_scores >= min_score)\n",
    "\n",
    "    # Return filtered detections\n",
    "    final_boxes = detection_boxes[indices]\n",
    "    final_classes = detection_classes[indices]\n",
    "    final_scores = detection_scores[indices]\n",
    "\n",
    "    return final_boxes, final_classes, final_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \n",
    "    \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \n",
    "    \"street sign\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \n",
    "    \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \n",
    "    \"zebra\", \"giraffe\", \"hat\", \"backpack\", \"umbrella\", \"shoe\", \n",
    "    \"eye glasses\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \n",
    "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \n",
    "    \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \n",
    "    \"bottle\", \"plate\", \"wine glass\", \"cup\", \"fork\", \"knife\", \n",
    "    \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \n",
    "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"mirror\", \"dining table\", \n",
    "    \"window\", \"desk\", \"toilet\", \"door\", \"tv\", \"laptop\", \"mouse\", \n",
    "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \n",
    "    \"toaster\", \"sink\", \"refrigerator\", \"blender\", \"book\", \"clock\", \n",
    "    \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\", \n",
    "    \"hair brush\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_person(boxes, classes, scores):\n",
    "    # Define the class index for \"person\"\n",
    "    person_index = class_names.index('person') + 1\n",
    "    # Initialize the highest score and corresponding box and class\n",
    "    highest_score = -1\n",
    "    highest_box = None\n",
    "    highest_class = None\n",
    "\n",
    "    # Iterate over all the classes\n",
    "    for i in range(len(classes)):\n",
    "        # Check if the class is \"person\" and if its score is higher than the highest score found so far\n",
    "        if classes[i] == person_index and scores[i] > highest_score:\n",
    "            highest_score = scores[i]\n",
    "            highest_box = boxes[i]\n",
    "            highest_class = classes[i]\n",
    "\n",
    "    # Return the highest scoring \"person\" box and class\n",
    "    return highest_box, highest_class, highest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pixel_coordinates(bbox, input_frame):\n",
    "    ymin, xmin, ymax, xmax = bbox\n",
    "    ymin = int(ymin * input_frame.shape[0])\n",
    "    xmin = int(xmin * input_frame.shape[1])\n",
    "    ymax = int(ymax * input_frame.shape[0])\n",
    "    xmax = int(xmax * input_frame.shape[1])\n",
    "    return [ymin, xmin, ymax, xmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(image, boxes, classes, scores):\n",
    "\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i]\n",
    "        class_id = classes[i]\n",
    "        score = scores[i]\n",
    "\n",
    "        # Get the bounding box coordinates\n",
    "        ymin, xmin, ymax, xmax = convert_to_pixel_coordinates(box, image)\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "        # Prepare the label\n",
    "        label = f\"{class_names[int(class_id)-1]}: {score:.2f}\"\n",
    "\n",
    "        # Put the label on the image\n",
    "        cv2.putText(image, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Use the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_object(cap, bbox, tracker, frame):\n",
    "    # Initialize tracker with the first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read a new frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox = tracker.update(frame)\n",
    "\n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            p1 = (int(bbox[1]), int(bbox[0]))\n",
    "            p2 = (int(bbox[3]), int(bbox[2]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "            return True, bbox\n",
    "        else:\n",
    "            return False, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(\"./test_img/person1.mp4\")\n",
    "\n",
    "# Create a tracker\n",
    "tracking_mode = False\n",
    "bbox = (0, 0, 0, 0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if not tracking_mode:\n",
    "        input_frame = preprocess(frame)\n",
    "\n",
    "        # Run the model\n",
    "        outputs = model(input_frame)\n",
    "\n",
    "        # Postprocess the outputs\n",
    "        boxes, classes, scores = postprocess(outputs)\n",
    "        boxes, classes, scores = get_top_person(boxes, classes, scores)\n",
    "\n",
    "        if boxes is not None and scores > 0.7:\n",
    "            frame = visualize_detections(frame, [boxes], [classes], [scores])\n",
    "            # Switch to tracking mode if a person is detected\n",
    "            bbox = convert_to_pixel_coordinates(boxes, frame)\n",
    "            cv2.imshow('Tracker', frame)\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "            tracking_mode = True\n",
    "\n",
    "            ymin, xmin, ymax, xmax = bbox\n",
    "\n",
    "# convert to (x, y, w, h)\n",
    "            # x = xmin\n",
    "            # y = ymin\n",
    "            # w = xmax - xmin\n",
    "            # h = ymax - ymin\n",
    "\n",
    "            center_x = int((xmin + xmax) / 2)\n",
    "            center_y = int((ymin + ymax) / 2)\n",
    "\n",
    "            # Calculate the new width and height based on the original bounding box\n",
    "            new_width = int((xmax - xmin) * 0.5)  # 50% of the original width\n",
    "            new_height = int((ymax - ymin) * 0.5)  # 50% of the original height\n",
    "\n",
    "            # Calculate the new coordinates of the target rectangle\n",
    "            xmin = center_x - int(new_width / 2)\n",
    "            ymin = center_y - int(new_height / 2)\n",
    "            xmax = center_x + int(new_width / 2)\n",
    "            ymax = center_y + int(new_height / 2)\n",
    "\n",
    "            x = xmin\n",
    "            y = ymin\n",
    "            w = xmax - xmin\n",
    "            h = ymax - ymin\n",
    "            # These are the top-left and bottom-right corners of the target rectangle\n",
    "\n",
    "            # new bbox for tracker\n",
    "            bbox_for_tracker = (x, y, w, h)\n",
    "            tracker.init(frame, bbox_for_tracker)\n",
    "        elif boxes is not None and scores < 0.7:\n",
    "            frame = visualize_detections(frame, [boxes], [classes], [scores])\n",
    "            # Switch to tracking mode if a person is detected\n",
    "            bbox = convert_to_pixel_coordinates(boxes, frame)\n",
    "            cv2.imshow('Tracker', frame)\n",
    "        else:\n",
    "            cv2.imshow('Tracker', frame)\n",
    "    else:\n",
    "        try:\n",
    "            ok, bbox = tracker.update(frame)\n",
    "        except cv2.error as e:\n",
    "            print(\"Tracking error: \", e)\n",
    "            tracking_mode = False\n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 225), 2, 1)\n",
    "            label = f\"Tracking mode\"\n",
    "        # Put the label on the image\n",
    "            cv2.putText(frame, label, (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 225), 2)\n",
    "            cv2.imshow('Tracker', frame)\n",
    "        if not ok:\n",
    "            # If tracking failed, switch back to detection mode\n",
    "            tracking_mode = False\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
